{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\n\nimport numpy as np\nimport torch\nfrom catboost.datasets import msrank_10k\nfrom sklearn.preprocessing import StandardScaler\n\nfrom typing import List\n\n\nclass ListNet(torch.nn.Module):\n    def __init__(self, num_input_features: int, hidden_dim: int):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        # укажите архитектуру простой модели здесь\n        self.model = nn.Sequential(\n            nn.Linear(num_input_features, self.hidden_dim),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.3),\n            nn.Linear(self.hidden_dim, 1)\n        )\n\n    def forward(self, input_1: torch.Tensor) -> torch.Tensor:\n        logits = self.model(input_1)\n        return logits\n\n\nclass Solution:\n    def __init__(self, n_epochs: int = 5, listnet_hidden_dim: int = 30,\n                 lr: float = 0.001, ndcg_top_k: int = 10):\n        self._prepare_data()\n        self.num_input_features = self.X_train.shape[1]\n        self.ndcg_top_k = ndcg_top_k\n        self.n_epochs = n_epochs\n\n        self.model = self._create_model(\n            self.num_input_features, listnet_hidden_dim)\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n\n    def _get_data(self) -> List[np.ndarray]:\n        train_df, test_df = msrank_10k()\n\n        X_train = train_df.drop([0, 1], axis=1).values\n        y_train = train_df[0].values\n        query_ids_train = train_df[1].values.astype(int)\n\n        X_test = test_df.drop([0, 1], axis=1).values\n        y_test = test_df[0].values\n        query_ids_test = test_df[1].values.astype(int)\n\n        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n\n    def _prepare_data(self) -> None:\n        (X_train, y_train, self.query_ids_train,\n            X_test, y_test, self.query_ids_test) = self._get_data()\n        # допишите ваш код здесь\n        \n        X_train = self._scale_features_in_query_groups(\n            X_train, self.query_ids_train)\n        X_test = self._scale_features_in_query_groups(\n            X_test, self.query_ids_train)\n        \n        self.X_train = torch.FloatTensor(X_train)\n        self.X_test = torch.FloatTensor(X_test)\n        \n        self.ys_train = torch.FloatTensor(y_train)\n        self.ys_test = torch.FloatTensor(y_test)\n\n    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n                                        inp_query_ids: np.ndarray) -> np.ndarray:\n        # допишите ваш код здесь\n        for cur_id in np.unique(inp_query_ids):\n            mask = (inp_query_ids == cur_id)\n            tmp_array = inp_feat_array[mask]\n            scaler = StandardScaler()\n            inp_feat_array[mask] = scaler.fit_transform(tmp_array)\n        \n        return inp_feat_array\n\n    def _create_model(self, listnet_num_input_features: int,\n                      listnet_hidden_dim: int) -> torch.nn.Module:\n        torch.manual_seed(0)\n        # допишите ваш код здесь\n        net = ListNet(num_input_features=listnet_num_input_features,\n                     hidden_dim=listnet_hidden_dim)\n        return net\n\n    def fit(self) -> List[float]:\n        # допишите ваш код здесь\n        metrics = []\n        for epoch_no in range(1, self.n_epochs + 1):\n            self._train_one_epoch()\n            ep_metric = self._eval_test_set()\n            metrics.append(ep_metric)\n        return matrics\n    \n    def save_model(self, path='listnet_lec3.pth'):\n        f = open(path, 'wb')\n        torch.save(self.model.state_dict, f)\n        \n    def load_model(self, path='listnet_lec3.pth'):\n        f = open(path, 'rb')\n        state_dict = torch.load(f)\n        self.model.load_state_dict(state_dict)\n\n    def _calc_loss(self, batch_ys: torch.FloatTensor,\n                   batch_pred: torch.FloatTensor) -> torch.FloatTensor:\n        # допишите ваш код здесь\n        P_y_i = torch.softmax(batch_ys, dim=0)\n        P_z_i = torch.softmax(batch_pred, dim=0)\n        return -torch.sum(P_y_i * torch.log(P_z_i/P_y_i))\n\n    def _train_one_epoch(self) -> None:\n        self.model.train()\n        # допишите ваш код здесь\n        for cur_id in np.unique(self.query_ids_train):\n            mask_train = (self.query_ids_train == cur_id)\n            batch_X = self.X_train[mask_train]\n            batch_ys = self.ys_train[mask_train]\n            \n            self.optimizer.zero_grad()\n            batch_pred = self.model(batch_X).reshape(-1,)\n            batch_loss = self._calc_loss(batch_ys, batch_pred)\n            batch_loss.backward(retain_graph=True)\n            self.optimizer.step()\n\n    def _eval_test_set(self) -> float:\n        with torch.no_grad():\n            self.model.eval()\n            ndcgs = []\n            # допишите ваш код здесь\n            for cur_id in np.unique(self.query_ids_test):\n                mask = (self.query_ids_test == cur_id)\n                X_test_tmp = self.X_test[mask]\n                valid_pred = self.model(X_test_tmp)\n                ndcg_score = self._ndcg_k(\n                    self.ys_test[mask], valid_pred, self.ndcg_top_k)\n                if np.isnan(ndcg_score):\n                    ndcgs.append(0)\n                    continue\n                ndcgs.append(ndcg_score)\n            return np.mean(ndcgs)\n\n    def _ndcg_k(self, ys_true: torch.Tensor, ys_pred: torch.Tensor,\n                ndcg_top_k: int) -> float:\n        # допишите ваш код здесь\n        def dcg(ys_true, ys_pred):\n            _, argsort = torch.sort(ys_pred, descending=True, dim=0)\n            argsort = argsort[:ndcg_top_k]\n            ys_true_sorted = ys_true[argsort]\n            ret = 0\n            for i, l in enumerate(ys_true_sorted, 1):\n                ret += (2 ** l - 1) / math.log2(1 + i)\n            return ret\n        ideal_dcg = dcg(ys_true, ys_true)\n        pred_dcg = dcg(ys_true, ys_pred)\n        return (pred_dcg / ideal_dcg).item()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T13:59:58.570137Z","iopub.execute_input":"2024-04-01T13:59:58.570600Z","iopub.status.idle":"2024-04-01T13:59:58.606602Z","shell.execute_reply.started":"2024-04-01T13:59:58.570569Z","shell.execute_reply":"2024-04-01T13:59:58.605197Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = msrank_10k()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T13:28:51.683239Z","iopub.execute_input":"2024-04-01T13:28:51.684188Z","iopub.status.idle":"2024-04-01T13:28:54.429445Z","shell.execute_reply.started":"2024-04-01T13:28:51.684135Z","shell.execute_reply":"2024-04-01T13:28:54.428049Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}